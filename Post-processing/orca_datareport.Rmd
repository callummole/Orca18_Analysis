---
title: 'Silent Failures in Automation. Pilot dataset Calculating Measures and Descriptive Plotting'
author: "Callum Mole"
output:
  html_document:
    df_print: paged
  html_notebook:
    fig_caption: yes
  pdf_document:
    fig_caption: yes
  word_document:
    fig_caption: yes
---

## Introduction

This document serves as a report for a first run of the pre-registered experiment https://osf.io/s6vam/. The experiment examines silent failures in a highly controlled setting. Each trial starts with automated steering. In some trials a bias is introduced that causes the vehicle to veer off the road either suddenly (within 1.5 s) or gradually (~ 4 s). Participants are required to keep within the road edges and intervene if they feel that it is necessary. They complete the task without distraction or with a easy or difficult distraction. There are also two bend radii used: sharp (40 m) or gradual (80 m).

```{r Load preliminaries, include=FALSE, warning=FALSE}

library("tidyverse")
library(magrittr) #for extra pipe functions
library(cowplot)
library("wesanderson")

#theme for plots on TRANSITION grant.
theme_transition <- theme_classic() +
  theme(strip.background = element_rect(fill=NA,color=NA), 
        strip.text = element_text(face="bold",colour="black",size="8"), 
        axis.title = element_text(face="bold",colour="black",size="8"),
        axis.text.x = element_text(vjust=-.5),
        axis.text.y = element_text(vjust=.5),
        axis.text = element_text(face="plain",colour="black",size="7"),
        legend.text = element_text(face="plain",colour="black",size="7"),
        legend.title = element_text(face="bold",colour="black",size="8"),
        legend.key = element_blank(),
        panel.grid.major.y = element_line(color="grey85",size=.2, linetype = 2))

```


```{r Load data, echo=FALSE, message=FALSE, warning=FALSE}

#set working directory to folder that hosts the binary files.
setwd("C:/Users/psccmo/Orca18_Analysis/Post-Processing/")

#load steergaze data

loadsteergazedata <- function(){
  steergazedata <- readRDS("orca_steergazedata.rds")  
  
  steergazedata <- steergazedata %>% 
  mutate(bend = ifelse(trialtype_signed < 0, "left", "right"))
  
  steergazedata <- steergazedata %>% 
  rename(SWV = SWA) %>% 
  mutate(SWA = SWV * 90)

  steergazedata <- steergazedata %>% 
  mutate(world_x_mirrored = if_else(bend == "left", World_x * -1, World_x),
         hangle_mirrored = if_else(bend == "left", hangle * -1, hangle),
         SWA_mirrored = if_else(bend == "left", SWA * -1, SWA),
         SWV_mirrored = if_else(bend == "left", SWV * -1, SWV))

  steergazedata$ppid <- as.factor(steergazedata$ppid)
  steergazedata$radius <- as.factor(steergazedata$radius)
  steergazedata$yawrate_offset <- as.factor(steergazedata$yawrate_offset)
  steergazedata$cogload <- as.factor(steergazedata$cogload)
    
  #create new column called failure type.
  steergazedata <- steergazedata %>% 
  mutate(failure_type = yawrate_offset)

  
  #refactor.
  levels(steergazedata$failure_type)[1] = "Sudden"
  levels(steergazedata$failure_type)[2] = "Gradual"
  levels(steergazedata$failure_type)[3] = "None"
  levels(steergazedata$failure_type)[4] = "None"


  return(steergazedata)
}

steergazedata <- loadsteergazedata()


```


### Technical Errors

This experiment stands as a lesson for the need to conduct a full technical pilot - running a participant through the entire experiment then putting that data through the entire analysis workflow. Due to time pressures we often do _some_ piloting to ostensibly check data saving, condition indexing etc. But we do not very often take the time to process the data through analysis scripts. In this case the data looked like it was saving correctly when piloting. But there were two key errors. First, the distraction performance files were overwritten when the driver was also steering (we still have the baseline - no steering - distraction performance files). Secondly, the "unique" filename for saving individual trials did not include the yawrate offsets in the title. So, in effect these trials were overwritten and only the last six (randomised) trials were saved for each radii, irrespective of yawrates offsets.

This means that we only have a small amount of data to work with, and the amount of trials performed (or, to be more precise, saved) for each condition is random between conditions. Fig 1 shows how many trials we have. The expected trialcount for each condition is 180 trials in the dataset.



```{r data logging, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10.5,fig.height=4.5,fig.cap="Fig 1. Amount of trials in each condition"}

steergaze_trial <- steergazedata  %>% 
  group_by(ppid, radius, yawrate_offset, cogload, block, count, .drop = F) %>% 
  summarize(trialcode = first(trialcode))


steergaze_expanded_counts <- steergaze_trial %>% 
  ungroup() %>% 
  complete(ppid, radius, yawrate_offset, cogload, 
           fill = list(trialcode = 99)) %>% 
  group_by(radius, yawrate_offset, cogload, .drop = FALSE) %>% 
  tally()
           
expected_trialcount <- 30 * 6 #30 participants x 6 trials in each condition.

#change the yawrate_offsets to factors.
steergaze_expanded_counts <- steergaze_expanded_counts %>% 
  mutate(failure_type = case_when(yawrate_offset %in% c(-.2, .15) ~ "None",
                                  yawrate_offset == -9 ~ "Sudden",
                                  yawrate_offset == -1.5 ~ "Gradual"))

steergaze_expanded_counts$cogload <- factor(steergaze_expanded_counts$cogload, levels = c("None", "Easy", "Hard"))
steergaze_expanded_counts$failure_type <- factor(steergaze_expanded_counts$failure_type, levels = c("Sudden", "Gradual", "None"))


#plot counts.
ggplot(steergaze_expanded_counts, aes(y = n, x = factor(cogload), fill = factor(failure_type))) +
  facet_wrap(~radius) +
  theme_transition +
   geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_manual(values = rev(wes_palette("BottleRocket2", n=3)), name = "Failure Type") +
  xlab("Cog Load") +
  ylab("Amount of Trials") +
  scale_y_continuous(sec.axis = sec_axis(~./180 * 100, name = "Proportion of Expected Data [%]"))

```

Fig 1 shows that for the distraction conditions we only have 20-30 % of the expected data. For driving without distraction we have slightly more because there are two blocks. For the trials we do have we have complete steering and gaze data, so at the very least the reduced data set will be useful at tweaking the design for an improved re-run, and for developing the modelling architecture.

### Cognitive Load difficulty.

```{r load cognitive task data, echo=FALSE, message=FALSE, warning=FALSE}

file_path <- "D:/ORCA_DATA/Data" #filepath (~ means to look in user's working directory)
file_lists <- list(list.files(file_path, pattern = "Orca18_Distractor_1_(p|P)"),
                   list.files(file_path, pattern = "Orca18_Distractor_2_(p|P)")) #separate into two blocks so I can loop through.
EoT <- "EndofTrial" #text at end of EndofTrial files. These are the recorded counts at the end of the trial.
WiT <- "WithinTrial" #text at end of WithinTrial files. These are the RT responses within a trial. 

block = 0

#assign dataframes

EoT_dataframe <- data.frame(X=integer(),
                 ppid=character(), 
                 targetoccurence=double(), 
                 targetnumber=integer(),
                 trialn = integer(),
                 EoTScore1 = double(),
                 TargetCount1 = double(),
                 EoTScore2 = double(),
                 TargetCount2 = double(),
                 EoTScore3 = double(),
                 TargetCount3 = double(),
                 block = integer())

WiT_dataframe <- data.frame(X=integer(),
                 ppid=character(), 
                 targetoccurence=double(), 
                 targetnumber=integer(),
                 trialn = integer(),
                 CurrentAudio = character(),
                 RT = double(),
                 ResponseCategory = integer(),
                 Target1 = character(),
                 Target2 = character(),
                 Target3 = character(),
                 block = integer())



for (file_block in file_lists){ #loop through  each block so you can add a block number and add 6 to trial number.
  
  #we want to add 6 to the second block trialn.
  block = block + 1
  if (block == 1){
    trial_add = 0
  } else {
    trial_add = 6
  }
  
  for (file_name in file_block){
    
    #print(file_name)
    
    #separate dataframe if EoT or WiT
    
    if (grepl(EoT, file_name)){
    
      EoT_newdata <- read.csv(paste(file_path,'/',file_name, sep = "")) #if already exists add to data frame.
      
      #head(EoT_newdata)
      
      EoT_newdata <- EoT_newdata %>% 
        mutate(trialn = trialn + trial_add,
               block = block)
      
      EoT_dataframe <- dplyr::union(EoT_newdata, EoT_dataframe) #add to existing datframe  
        
            
    } else if  (grepl(WiT, file_name)) {
      WiT_newdata <- read.csv(paste(file_path,'/',file_name, sep = "")) #load WithinTrial data
      
      WiT_newdata <- WiT_newdata %>% 
        mutate(trialn = trialn + trial_add,
               block = block)
      
      WiT_dataframe <- dplyr::union(WiT_newdata, WiT_dataframe) #add to existing datframe  
        
    }
  }
}

#head(EoT_dataframe) #view start of dataframe.
#head(WiT_dataframe) #view start of dataframe.

```



```{r calculate measures, echo=FALSE, message=FALSE, warning=FALSE}
  
##### WITHIN TRIAL MEASURES ########


WiT_RTfiltered <- filter(WiT_dataframe, RT == -1 | RT >.1) # Returns dataframe for rows where RT was >.1 or -1 (no response) 

WiT_TruePos <- filter(WiT_RTfiltered, ResponseCategory == 1) #create new dataframe only including true positives
  
SummaryRTs <- WiT_TruePos %>% group_by(ppid, trialn) %>% summarise(
  targetnumber = first(targetnumber),
  targetoccurence = first(targetoccurence),
  meanRT = mean(RT),
  stdRT = sd(RT))

#Calculate the amount of each type of responses
SummaryCounts <- WiT_RTfiltered %>% group_by(ppid, trialn) %>% summarise(
  targetnumber = first(targetnumber),
  targetoccurence = first(targetoccurence),
  TruePos = sum(ResponseCategory==1),
  FalseNeg = sum(ResponseCategory==2), 
  FalsePos = sum(ResponseCategory==3),
  TrueNeg = sum(ResponseCategory==4), 
  TotalResponses=n())

SummaryCounts <- mutate(SummaryCounts, Perc_Correct = (TruePos + TrueNeg)/ TotalResponses)


####### END OF TRIAL MEASURES ########
  
#First, replace NA with Zeros for the following code to work. This means I can use the same code on all trials, even though some may have different amounts of targets.
EoT_dataframe[is.na(EoT_dataframe)] <- 0

#Calculate the error for each target.
EoT_dataframe <- mutate(EoT_dataframe, 
                        Error1 = EoTScore1 - TargetCount1,
                        Error2 = EoTScore2 - TargetCount2,
                        Error3 = EoTScore3 - TargetCount3)

#Calculate the total absolute error and divide by targetnumber
EoT_dataframe <- EoT_dataframe %>% 
  mutate(totalcounterror = abs(Error1) + abs(Error2) + abs(Error3),
         totaltargets = abs(TargetCount1) + abs(TargetCount2) + abs(TargetCount3),
         avgcounterror = totalcounterror / targetnumber,
         proportionalcounterror = totalcounterror / totaltargets
         )
                            




########### MERGE DATAFRAMES ############

#merges dataframes for trial measures
SummaryTrialMeasures <- merge(SummaryCounts, SummaryRTs, by = c("ppid","trialn"), all.x = TRUE)

#only select the columns we are interested in 
EoT_avgerror <- select(EoT_dataframe, ppid, trialn, targetnumber, targetoccurence, totalcounterror, totaltargets, avgcounterror, proportionalcounterror)

#merge within trial and EoT measures together
SummaryMeasures <- merge(SummaryTrialMeasures, EoT_avgerror, by = c("ppid","trialn"))

#drop some extra columns created by merging for some unimportant reasons
SummaryMeasures <- select(SummaryMeasures, -targetoccurence.x, -targetnumber.x, -targetoccurence.y, -targetnumber.y)

#head(SummaryMeasures)
```

We only have the cognitive performance for baseline (without steering). Here we plot three indices of performance: _Percentage Correct_ (PC, True positives + True negatives / total letters heard); _Reaction Time_ (RT, reaction time for True positives); _Proportional Absolute Count Error_ (average distance from the true count, expressed as a proportion of the total amount of targets heard).

```{r plot Cognitive Task Performance, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10.5,fig.height=4.5,fig.cap="Fig 2. Cognitive Task Performance. A) Percentage Correct. B) Reaction Time. C-D) Absolute Count Error"}

# box plots for absolute count error.

#so I do not repeat myself below
addscale <- scale_fill_manual(values = wes_palette("Cavalcanti1"), name = "Cognitive Load", labels = c("1"="Easy", "3"="Hard"))
changexlabels <- scale_x_discrete(name = "Cognitive Load", labels=c("1" = "Easy", "3" = "Hard"))

#Example 2: plot ACE for each targetnumber
p_rt <- ggplot(data=SummaryMeasures, aes(y=meanRT, x=factor(targetnumber), fill = factor(targetnumber))) + 
  geom_boxplot(outlier.size = 1) +
  addscale +
  theme_transition +
  changexlabels + ylab ("Mean RT for True Positives (s)")
  
p_pc <- ggplot(data=SummaryMeasures, aes(y=Perc_Correct, x=factor(targetnumber), fill = factor(targetnumber))) + 
  geom_boxplot(outlier.size = 1) +
  addscale +
  theme_transition +
  changexlabels + ylab ("Percentage of Targets Responded Correctly (%)")

p_ace <- ggplot(data=SummaryMeasures, aes(y=proportionalcounterror, x=factor(targetnumber), fill = factor(targetnumber))) + 
  geom_boxplot(outlier.size = 1) +
  addscale +
  theme_transition +
  changexlabels + ylab ("Average proportional error in estimated count")

legend <- get_legend(p_rt)
p <- plot_grid(p_rt + theme(legend.position="none"), 
               p_pc + theme(legend.position="none"), 
               p_ace + theme(legend.position="none"),
               labels = c("A", "B","C"), nrow=1)
p_legend <- plot_grid(p, legend, rel_widths = c(4,.5))
show(p_legend)

```
 
Fig 2 shows that people respond differently to each Cognitive Load condition. Participants react slower to heard target letters if they are listening for three targets as compared to one target (Fig 2A). Participants rarely make mistakes (i.e. responding to a distractor letter or not responding to a target letter) in the Easy Cognitive Load condition, they make more mistakes in the hard Cognitive Load condition (Fig 2B). 
 
The interpretation of the last measure, the count error (Fig 2C), is more nuanced. Assessing accuracy of estimated counts is tricky because the amount of occurences of each target in the _Hard_ condition is generally a third of the count of the target in the _Easy_ condition. It is worth noting that the total error (cumulative across multiple targets) is pretty identical across both conditions. How you use then use this total count error to take into account people are responding to more targets _Hard_ than _Easy_ is the debateable bit. For example, estimating five instead of six has the same total error as estimating zero, two, three, for target counts of one, two and three. Yet one could argue that the two responses are qualitatively different because in the second case the participant has entirely missed a target but got the other two spot on. To reflect this I've chosen to express this measure as a proportional of the total amount of targets heard (Fig 2C). In any case, people are only marginally less accurate on this measure in the _Hard_ cognitive load than for _Easy_. It seems that the more precise measures of RT and PC are better indicators of differences in performance.

Therefore, a quick eyeball of the baseline cognitive task performance suggests that people reacted slower and experienced greater difficulty in deciding the appropriate response when there were three targets as compared to when there was only one.

Let's see how this gets reflected in steering measures.

### Driver Takeover.

The pre-registration specifies two hypotheses relating to taking over control of the vehicle:

-	__H1__: Participants will react slower to silent failures as cognitive load increases (i.e. more time will elapsed from the yaw rate offset to the driver disengaging the automation).

-	__H2__: Participants will react with less aggression as cognitive load increases, bringing the vehicle back to the centre more slowly (i.e. they will be smoother and make less corrections). 

These two hypotheses will be analysed in turn.

#### H1: Speed of take-over

The pre-registration states that we will calculate two measures:

- RT from yawrate-drift onset to disengagement of the system via a button press (can be negative if they take over before the yaw-rate bias is introduced). I will refer to this measure as RT~takeover~.

- RT from yawrate-drift onset to first steering movement (RT~steer~).

For the purposes of a quick look at the pilot dataset I will only calculate RT~takeover~ for now.

<!-- 
Future plots:
- A birdseye plot showing the points at takeover and the subsequent trajectories would be illustrative. These would have to be reset to the same onset time  
- scatter plot showing whether onset time and/or pre-recorded trajectory choice influenced reaction times.
-->

```{r calculate RT takeover measure, echo=FALSE, message=FALSE, warning=FALSE}

### need to calculate RTs.
if (!exists("steergazedata")){
  #load steergaze data
  steergazedata <- loadsteergazedata()
  
}

#create function retrieving RT-takeover.
disengage_RT <- function(onsettime, timestamp_trial, autoflag){

  #pick first frame where autoflag == false, then take the timestamp and minus the onset_time
  auto_false <- which(autoflag == "FALSE")
  disengage_index <- first(auto_false)
  disengage_trialtime <- timestamp_trial[disengage_index]
  onset_time <- first(onsettime)
  RT <- disengage_trialtime - onset_time #can be negative
  return(RT)
}


#create factors
steergazedata$ppid <- as.factor(steergazedata$ppid)
steergazedata$radius <- as.factor(steergazedata$radius)
steergazedata$yawrate_offset <- as.factor(steergazedata$yawrate_offset)
steergazedata$cogload <- as.factor(steergazedata$cogload)

steergaze_trialavgs <- steergazedata  %>% 
  group_by(ppid, radius, yawrate_offset, cogload, block, count) %>% 
  summarize(RT = disengage_RT(OnsetTime, timestamp_trial, AutoFlag),
            disengaged = ifelse(is.na(RT), 0, 1) #whether or not they actually took over.
            )
 
#create new column called failure type.
steergaze_trialavgs <- steergaze_trialavgs %>% 
  mutate(failure_type = yawrate_offset)

#refactor.
levels(steergaze_trialavgs$failure_type)[1] = "Sudden"
levels(steergaze_trialavgs$failure_type)[2] = "Gradual"
levels(steergaze_trialavgs$failure_type)[3] = "None"
levels(steergaze_trialavgs$failure_type)[4] = "None"

#disengage %
disengage_perc <- steergaze_trialavgs %>% 
  ungroup() %>% 
  filter(failure_type == "None") %>% 
  summarise(pc = sum(disengaged) / n()) 
  

```

```{r plotting RT takeover, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10.5,fig.height=4.5,fig.cap="Fig 3. RT takeover across failure types"}

#first plot is the RTs across different failure types. Boxplots or density estimates are good option.

ggplot(steergaze_trialavgs, aes(x = RT, group = factor(failure_type), fill = factor(failure_type))) +
  geom_density(alpha = .8) +
  xlim(c(0,10)) +
  scale_fill_manual(values = rev(wes_palette("BottleRocket2",n=3)), name = "Failure Type") +
  theme_transition +
  xlab(expression("RT"["takeover"]*" (s)"))

```

Fig 3 shows massive differences in how quickly drivers disengage the automation after the yawrate onset. In the _None_ condition drivers disengaged the system in `r round(as.double(disengage_perc) * 100)` % of trials. Since drivers react at such different speeds across the three failure types the failure type conditions will be look at in turn.

```{r plotting RT takeover within failure type conditions, echo=FALSE, message=FALSE, warning=FALSE, fig.width=14,fig.height=4.5,fig.cap="Fig 4. RT takeover across cognitive loads"}

#first plot is the RTs across different failure types. Boxplots or density estimates are good option.

p_sudden <- ggplot(filter(steergaze_trialavgs, failure_type == "Sudden"), 
                   aes(x = RT, group = factor(cogload), col = factor(cogload), fill = factor(cogload))) +
  geom_histogram(alpha = .2, position = "identity", bins = 40, aes(y= ..density..), col =NA) +
  geom_density(size = 1.2, fill = NA) +
  xlim(c(0,NA)) +
  scale_fill_manual(values = wes_palette("Cavalcanti1"), name = "Cognitive Load") +
  scale_colour_manual(values = wes_palette("Cavalcanti1"), name = "Cognitive Load") +
  theme_transition +
  xlab(expression("RT"["takeover"]*" (s)")) 


  
p_gradual <- ggplot(filter(steergaze_trialavgs, failure_type == "Gradual"), 
                   aes(x = RT, group = factor(cogload), col = factor(cogload), fill = factor(cogload))) +
  geom_histogram(alpha = .2, position = "identity", bins = 40, aes(y= ..density..), col =NA) +
  geom_density(size = 1.2, fill = NA) +
  xlim(c(0,NA)) +
  scale_fill_manual(values = wes_palette("Cavalcanti1"), name = "Cognitive Load") +
  scale_colour_manual(values = wes_palette("Cavalcanti1"), name = "Cognitive Load") +
  theme_transition +
  xlab(expression("RT"["takeover"]*" (s)")) 

p_none <- ggplot(filter(steergaze_trialavgs, failure_type == "None"), 
                   aes(x = RT, group = factor(cogload), col = factor(cogload), fill = factor(cogload))) +
  geom_histogram(alpha = .2, position = "identity", bins = 40, aes(y= ..density..), col =NA) +
  geom_density(size = 1.2, fill = NA) +
  xlim(c(0,NA)) +
  scale_fill_manual(values = wes_palette("Cavalcanti1"), name = "Cognitive Load") +
  scale_colour_manual(values = wes_palette("Cavalcanti1"), name = "Cognitive Load") +
  theme_transition +
  xlab(expression("RT"["takeover"]*" (s)")) 

legend <- get_legend(p_sudden)
p_rt_takeover <- plot_grid(p_sudden + theme(legend.position="none"), 
               p_gradual + theme(legend.position="none"), 
               p_none + theme(legend.position="none"),
               labels = c("Sudden", "Gradual","No Failure"), nrow=1, hjust = -1)
p_rt_takeover_legend <- plot_grid(p_rt_takeover, legend, rel_widths = c(4,.5))
show(p_rt_takeover_legend)

  

```
Fig 4 shows cognitive load differences in RT~takeover~ within failure type. For Sudden failures (leftmost in Fig 4) there are clear difference between None, Easy, and Hard. People switch to manual mode quickest when not performing a distractor task; they switch slowest when the distractor task is more difficult. This difference is less pronounced for Gradual failures (middle) and No failures (right). Part of the difficulty in interpreting the distributions is due to the depleted dataset. In the Sudden condition all the data falls within fairly narrow regions (0-2s) so smooth density estimates are observed despite the relatively low numbers of trials. In the Gradual Failure and No Failure conditions the data is spread out over a wider range so there begin to be 'gaps' in the distribution (effectively, unsampled space). Therefore the density estimates are bumpier and it is more difficult to see clear differences. The histograms in the background how the gaps and spikes correspond to bumps in the density estimate. Nevertheless, in the Gradual condition I am tempted to predict that with more data we would see clear differences begin to emerge between the no load condition and when the driver is cognitively loaded. 

__H1 Summary__: of course this needs inferential statistics to support my eyeballing, but I will tentatively suggest that reaction time to silent failures does indeed increase as cognitive load increases, though this effect depends on the severity of the failure.

```{r modelling RT, echo=FALSE, message=FALSE, warning=FALSE}



```

#### H2: Steering Response

Here we analyse the driver response after taking over control. First, we will plot some average trajectories. 

<!-- First off:

Filter out trials where the participant took over.
Average trajectory plots.
Average steering bias over time.
Average Steering wheel velocity over time.

-->



```{r filtering takeover trials, echo=FALSE, message=FALSE, warning=FALSE, fig.width=5,fig.height=5,fig.cap="Fig 5. A) Average trajectories, B) Shown as steering bias"}

#can use AutoFlag to select manual control periods.

#add trialid to frame by frame dataset because the current one doesn't include enough unique information
steergazedata <- steergazedata %>% 
  mutate(trialid = paste(ppid, radius, yawrate_offset, cogload, block, count, sep = "_"))


#only select the trials with manual control in them.
steergaze_manual <- steergazedata %>% 
  filter(AutoFlag == FALSE)

### Reset trial so they all start at around [0,0] 
steergaze_manual <- steergaze_manual %>% 
  ungroup() %>% 
  group_by(trialid) %>%
  mutate(timestamp_zero = timestamp_trial - timestamp_trial[1],
         f = seq(1:n()))

#create trial list for sample one trial
triallist <- steergaze_manual %>% 
  ungroup() %$% 
  unique(trialid) 


head(steergaze_manual)


########### NEED TO ROTATE AROUND START OF BEND #########

#create function that takes an x and z and rotates it back to origin.
resettrajectory <- function(df){
  
  #X,z should be vectors of positions in the world.
  #first_yaw should be the world orientation of the first frame of the trajectory
  #first_sb should be the steering bias of the first frame.
  #rotate round origin.
  #the origin of the bend is +rads, +16 m
  
  x = df$world_x_mirrored
  z = df$World_z
  rads = first(df$radii)
  failure_type = df$failure_type[1]
  cogload = df$cogload[1]
  
  bend_origin_x = rads
  bend_origin_z = 16
  
  
  #z = z - bend_start
  #x = x - rads
  #first retrieve the angle between world_x and world_z and the abscissa, relative to the origin. 

  x = x - bend_origin_x
  z = z - bend_origin_z
 
  x1 = first(x)
  z1= first(z)
  
  
  length_from_bend_origin = sqrt( (x1)^2 + (z1 )^2 )   #b
  length_from_bend_start = sqrt( (x1 - -bend_origin_x) ^2 + (z1 )^2 ) #c
  
  #print(length_from_bend_origin)
  #print(length_from_bend_start)
  
  #use cosine rule to find rotation angle
  numerator = (length_from_bend_origin^2 + rads^2 - length_from_bend_start^2)
  denominator =  2 * length_from_bend_origin * rads
  rotation_angle = acos(  numerator / denominator )

  x_rotate <- cos(rotation_angle) * (x ) - 
    sin(rotation_angle) * (z) 
  z_rotate <- sin(rotation_angle) * (x) + 
    cos(rotation_angle) * (z) 
  
  #reset to zero, but conserve steering bias offset. The other way of doing this would be to minus the closest point.
  x_rotate <- x_rotate + bend_origin_x
  z_rotate <- z_rotate + bend_origin_z 
  
  ret <- data_frame(world_x_rotate = x_rotate,
             world_z_rotate = z_rotate,
             radius = rads,
             failure_type = failure_type,
             cogload = cogload)
  
  return(ret)

}


#load track data
track_80 <- read.csv("track_with_edges_orca_80.csv")
track_40 <- read.csv("track_with_edges_orca_40.csv")

steergaze_manual_rotated <- steergaze_manual %>% 
  group_by(trialid) %>% 
  do(resettrajectory(.))

head(steergaze_manual_rotated_40)

steergaze_manual_rotated_40 <- steergaze_manual_rotated %>% 
  filter(radius == 40)

p_40 <- ggplot(data = steergaze_manual_rotated_40, aes(x = world_x_rotate, y= world_z_rotate, col = factor(failure_type))) +
  geom_path(aes(group = trialid), alpha = .3) +
  scale_colour_manual(values = rev(wes_palette("BottleRocket2",n=3)), name = "Failure Type") +
  geom_path(data = track_40, aes(x = midlinex, y=midlinez), colour = "grey", linetype = "dashed") +
  geom_path(data = track_40, aes(x = outsidex, y=outsidez), colour = "grey") +
  geom_path(data = track_40, aes(x = insidex, y=insidez), colour = "grey") +
  xlim(c(min(track_40$outsidex), max(steergaze_manual_rotated_40$world_x_rotate))) +
  ylim(c(16,60))

show(p_40)

head(mytrial)
#now try to rotate it
steergaze_manual_rotated <- mytrial %>% 
  group(trialid) %>% 
  do(resettrajectory(.$world_x_mirrored, .$World_z, first(.$WorldYaw), first(.$SteeringBias), first(.$radii)))

p_raw + 
  geom_path(data = rotate_mytrial, aes(x = world_x_rotate, y=world_z_rotate), colour = "red") 

show(p_raw)
  

```


### Gaze

### Steering and Gaze

### with/without automation.

### plots of steering trajectories.

### plots of gaze. 


<!-- 
Future Analysis:
- Are any of the variables affected by onset time?
- Are any of the variables affected by which automated trajectory is being played? 

- Plot the distribution of when they took over in the trial.
- And also the x z position of when they took over.
-->
