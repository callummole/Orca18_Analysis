---
title: 'Silent Failures in Automation. Pilot dataset Report'
author: "Callum Mole"
output:
  html_document:
    df_print: paged
  html_notebook:
    fig_caption: yes
  pdf_document:
    fig_caption: yes
  word_document:
    fig_caption: yes
---

## Introduction

This document serves as a report for a first run of the pre-registered experiment https://osf.io/s6vam/. The experiment examines silent failures in a highly controlled setting. Each trial starts with automated steering. In some trials a bias is introduced that causes the vehicle to veer off the road either suddenly (within 1.5 s) or gradually (~ 4 s). Participants are required to keep within the road edges and intervene if they feel that it is necessary. They complete the task without distraction or with a easy or difficult distraction. There are also two bend radii used: sharp (40 m) or gradual (80 m).

```{r Load preliminaries, include=FALSE, warning=FALSE}

library("tidyverse")
library(magrittr) #for extra pipe functions
library(cowplot)
library("wesanderson")

#theme for plots on TRANSITION grant.
theme_transition <- theme_classic() +
  theme(strip.background = element_rect(fill=NA,color=NA), 
        strip.text = element_text(face="bold",colour="black",size="8"), 
        axis.title = element_text(face="bold",colour="black",size="8"),
        axis.text.x = element_text(vjust=-.5),
        axis.text.y = element_text(vjust=.5),
        axis.text = element_text(face="plain",colour="black",size="7"),
        legend.text = element_text(face="plain",colour="black",size="7"),
        legend.title = element_text(face="bold",colour="black",size="8"),
        legend.key = element_blank(),
        panel.grid.major.y = element_line(color="grey85",size=.2, linetype = 2))

```


```{r Load data, echo=FALSE, message=FALSE, warning=FALSE}

#set working directory to folder that hosts the binary files.
setwd("C:/Users/psccmo/Orca18_Analysis/Post-Processing/")

#load steergaze data
steergazedata <- readRDS("orca_steergazedata.rds")

#add left bend
steergazedata <- steergazedata %>% 
  mutate(bend = ifelse(trialtype_signed < 0, "left", "right"))

steergazedata[steergazedata$bend == "left", "hangle"] <- steergazedata[steergazedata$bend == "left", "hangle"]*-1 



steergazedata <- steergazedata %>% 
  rename(SWV = SWA) %>% 
  mutate(SWA = SWV * 90)

```


### Technical Errors

This experiment stands as a lesson for the need to conduct a full technical pilot - running a participant through the entire experiment then putting that data through the entire analysis workflow. Due to time pressures we often do _some_ piloting to ostensibly check data saving, condition indexing etc. But we do not very often take the time to process the data through analysis scripts. In this case the data looked like it was saving correctly when piloting. But there were two key errors. First, the distraction performance files were overwritten when the driver was also steering (we still have the baseline - no steering - distraction performance files). Secondly, the "unique" filename for saving individual trials did not include the yawrate offsets in the title. So, in effect these trials were overwritten and only the last six (randomised) trials were saved for each radii, irrespective of yawrates offsets.

This means that we only have a small amount of data to work with, and the amount of trials performed (or, to be more precise, saved) for each condition is random between conditions. Fig 1 shows how many trials we have. The expected trialcount for each condition is 180 trials in the dataset.



```{r data logging, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10.5,fig.height=4.5,fig.cap="Fig 1. Amount of trials in each condition"}

steergaze_trial <- steergazedata  %>% 
  group_by(ppid, radius, yawrate_offset, cogload, block, count, .drop = F) %>% 
  summarize(trialcode = first(trialcode))


steergaze_expanded_counts <- steergaze_trial %>% 
  ungroup() %>% 
  complete(ppid, radius, yawrate_offset, cogload, 
           fill = list(trialcode = 99)) %>% 
  group_by(radius, yawrate_offset, cogload, .drop = FALSE) %>% 
  tally()
           
expected_trialcount <- 30 * 6 #30 participants x 6 trials in each condition.

#change the yawrate_offsets to factors.
steergaze_expanded_counts <- steergaze_expanded_counts %>% 
  mutate(failure_type = case_when(yawrate_offset %in% c(-.2, .15) ~ "None",
                                  yawrate_offset == -9 ~ "Sudden",
                                  yawrate_offset == -1.5 ~ "Gradual"))

steergaze_expanded_counts$cogload <- factor(steergaze_expanded_counts$cogload, levels = c("None", "Easy", "Hard"))
steergaze_expanded_counts$failure_type <- factor(steergaze_expanded_counts$failure_type, levels = c("None", "Gradual", "Sudden"))

#plot counts.
ggplot(steergaze_expanded_counts, aes(y = n, x = factor(cogload), fill = factor(failure_type))) +
  facet_wrap(~radius) +
  theme_transition +
   geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_manual(values = wes_palette("BottleRocket2"), name = "Failure Type") +
  xlab("Cog Load") +
  ylab("Amount of Trials") +
  scale_y_continuous(sec.axis = sec_axis(~./180 * 100, name = "Proportion of Expected Data [%]"))

```

Fig 1 shows that for the distraction conditions we only have 20-30 % of the expected data. For driving without distraction we have slightly more because there are two blocks. For the trials we do have we have complete steering and gaze data, so at the very least the reduced data set will be useful at tweaking the design for an improved re-run, and for developing the modelling architecture.

### Cognitive Load difficulty.

 - baseline differences in reaction time and % correct. 

```{r load cognitive task data, echo=FALSE, message=FALSE, warning=FALSE}

file_path <- "D:/ORCA_DATA/Data" #filepath (~ means to look in user's working directory)
file_lists <- list(list.files(file_path, pattern = "Orca18_Distractor_1_(p|P)"),
                   list.files(file_path, pattern = "Orca18_Distractor_2_(p|P)")) #separate into two blocks so I can loop through.
EoT <- "EndofTrial" #text at end of EndofTrial files. These are the recorded counts at the end of the trial.
WiT <- "WithinTrial" #text at end of WithinTrial files. These are the RT responses within a trial. 

block = 0

#assign dataframes

EoT_dataframe <- data.frame(X=integer(),
                 ppid=character(), 
                 targetoccurence=double(), 
                 targetnumber=integer(),
                 trialn = integer(),
                 EoTScore1 = double(),
                 TargetCount1 = double(),
                 EoTScore2 = double(),
                 TargetCount2 = double(),
                 EoTScore3 = double(),
                 TargetCount3 = double(),
                 block = integer())

WiT_dataframe <- data.frame(X=integer(),
                 ppid=character(), 
                 targetoccurence=double(), 
                 targetnumber=integer(),
                 trialn = integer(),
                 CurrentAudio = character(),
                 RT = double(),
                 ResponseCategory = integer(),
                 Target1 = character(),
                 Target2 = character(),
                 Target3 = character(),
                 block = integer())



for (file_block in file_lists){ #loop through  each block so you can add a block number and add 6 to trial number.
  
  #we want to add 6 to the second block trialn.
  block = block + 1
  if (block == 1){
    trial_add = 0
  } else {
    trial_add = 6
  }
  
  for (file_name in file_block){
    
    print(file_name)
    
    #separate dataframe if EoT or WiT
    
    if (grepl(EoT, file_name)){
    
      EoT_newdata <- read.csv(paste(file_path,'/',file_name, sep = "")) #if already exists add to data frame.
      
      head(EoT_newdata)
      
      EoT_newdata <- EoT_newdata %>% 
        mutate(trialn = trialn + trial_add,
               block = block)
      
      EoT_dataframe <- dplyr::union(EoT_newdata, EoT_dataframe) #add to existing datframe  
        
            
    } else if  (grepl(WiT, file_name)) {
      WiT_newdata <- read.csv(paste(file_path,'/',file_name, sep = "")) #load WithinTrial data
      
      WiT_newdata <- WiT_newdata %>% 
        mutate(trialn = trialn + trial_add,
               block = block)
      
      WiT_dataframe <- dplyr::union(WiT_newdata, WiT_dataframe) #add to existing datframe  
        
    }
  }
}

#head(EoT_dataframe) #view start of dataframe.
#head(WiT_dataframe) #view start of dataframe.

```


Now we have loaded the cognitive load data, let's crunch the numbers.

```{r calculate measures, echo=FALSE, message=FALSE, warning=FALSE}
  
##### WITHIN TRIAL MEASURES ########


WiT_RTfiltered <- filter(WiT_dataframe, RT == -1 | RT >.1) # Returns dataframe for rows where RT was >.1 or -1 (no response) 

WiT_TruePos <- filter(WiT_RTfiltered, ResponseCategory == 1) #create new dataframe only including true positives
  
SummaryRTs <- WiT_TruePos %>% group_by(ppid, trialn) %>% summarise(
  targetnumber = first(targetnumber),
  targetoccurence = first(targetoccurence),
  meanRT = mean(RT),
  stdRT = sd(RT))

SummaryCounts <- mutate(SummaryCounts, Perc_Correct = (TruePos + TrueNeg)/ TotalResponses)


####### END OF TRIAL MEASURES ########
  
#First, replace NA with Zeros for the following code to work. This means I can use the same code on all trials, even though some may have different amounts of targets.
EoT_dataframe[is.na(EoT_dataframe)] <- 0

#Calculate the error for each target.
EoT_dataframe <- mutate(EoT_dataframe, 
                        Error1 = EoTScore1 - TargetCount1,
                        Error2 = EoTScore2 - TargetCount2,
                        Error3 = EoTScore3 - TargetCount3)

#Calculate the total absolute error and divide by targetnumber
EoT_dataframe <- mutate(EoT_dataframe, AvgCountError = (abs(Error1) + abs(Error2) + abs(Error3)) / targetnumber)



########### MERGE DATAFRAMES ############

#merges dataframes for trial measures
SummaryTrialMeasures <- merge(SummaryCounts, SummaryRTs, by = c("ppid","trialn"), all.x = TRUE)

#only select the columns we are interested in 
EoT_avgerror <- select(EoT_dataframe, ppid, trialn, targetnumber, targetoccurence, AvgCountError)

#merge within trial and EoT measures together
SummaryMeasures <- merge(SummaryTrialMeasures, EoT_avgerror, by = c("ppid","trialn"))

#drop some extra columns created by merging for some unimportant reasons
SummaryMeasures <- select(SummaryMeasures, -targetoccurence.x, -targetnumber.x, -targetoccurence.y, -targetnumber.y)

```

```{r plotting for informal hypothesis exploration, echo=FALSE, message=FALSE, warning=FALSE}

#plot comparison to assess whether people respond differently to the two cognitive tasks when not driving.


```
 
### Steering.

### Gaze

### Steering and Gaze

### with/without automation.

### plots of steering trajectories.

### plots of gaze. 


